"""
scorer.py â€” AIã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
åé›†ã—ãŸæƒ…å ±ã«å¯¾ã—ã¦ã€Œæ–°ã—ã•ã€ã€Œå¸Œå°‘æ€§ã€ã€Œä¿¡é ¼åº¦ã€ã‚’è©•ä¾¡ã—ã€
ç·åˆå„ªå…ˆåº¦ã‚¹ã‚³ã‚¢(0-100)ã‚’ä»˜ä¸ã™ã‚‹ã€‚
"""

import re
from datetime import datetime, timedelta

# â”€â”€ å¸Œå°‘æ€§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé«˜ã‚¹ã‚³ã‚¢ â†’ å¸Œå°‘ãƒ»é™å®šï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RARITY_HIGH = [
    "é™å®š", "æ•°é‡é™å®š", "å—æ³¨ç”Ÿç”£", "å®Œå…¨å—æ³¨", "ä¸€ç•ªãã˜", "æŠ½é¸",
    "å…ˆç€", "åˆå›é™å®š", "ç‰¹å…¸", "ã‚·ãƒªã‚¢ãƒ«", "ãƒŠãƒ³ãƒãƒªãƒ³ã‚°", "ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ",
    "ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚º", "ãƒ¬ã‚¢", "exclusive", "limited"
]
RARITY_MED = [
    "å—æ³¨", "äºˆç´„", "å…ˆè¡Œ", "ã‚³ãƒ©ãƒœ", "æœŸé–“é™å®š", "åº—èˆ—é™å®š",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³é™å®š", "ä¼šå ´é™å®š", "ãƒ•ã‚§ã‚¢"
]

# â”€â”€ ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆã‚¹ã‚³ã‚¢åŠ ç‚¹ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TRUST_HIGH_DOMAINS = [
    "animate.co.jp", "ichibankuji.com", "bandaispirits.co.jp",
    "aniplex.co.jp", "jump.shueisha.co.jp", "natalie.mu",
    "animatetimes.com", "prtimes.jp", "famitsu.com",
    "nijigenfes.jp", "collab-cafe.com", "lawson.co.jp"
]
TRUST_MED_DOMAINS = [
    "gamers.co.jp", "akibaoo.co.jp", "xlarge.jp",
    "horipro-stage.jp", "ufotablecinema.com"
]

# â”€â”€ å…¬å¼Xã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OFFICIAL_X_KEYWORDS = [
    "å…¬å¼", "official", "ã‚¢ãƒ‹ãƒ¡ã‚¤ãƒˆ", "ãƒãƒ³ãƒ€ã‚¤", "bandai",
    "aniplex", "ã‚¸ãƒ£ãƒ³ãƒ—", "jump", "ãƒ­ãƒ¼ã‚½ãƒ³", "lawson"
]

def score_freshness(date_str: str) -> int:
    """
    æ–°ã—ã•ã‚¹ã‚³ã‚¢ (0-40 ç‚¹)
    ç›´è¿‘7æ—¥:40 / 30æ—¥:30 / 90æ—¥:20 / 180æ—¥:10 / ãã‚Œä»¥ä¸Š:0
    """
    if not date_str:
        return 5  # æ—¥ä»˜ä¸æ˜ã¯ä½ã‚
    try:
        for fmt in ["%Y-%m-%d", "%Y/%m/%d"]:
            try:
                dt = datetime.strptime(date_str[:10], fmt)
                break
            except ValueError:
                continue
        else:
            return 5
        delta = (datetime.now() - dt).days
        if delta <= 7:   return 40
        if delta <= 30:  return 30
        if delta <= 90:  return 20
        if delta <= 180: return 10
        return 3
    except Exception:
        return 5

def score_rarity(content: str) -> int:
    """
    å¸Œå°‘æ€§ã‚¹ã‚³ã‚¢ (0-35 ç‚¹)
    é«˜å¸Œå°‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:+5/å€‹(æœ€å¤§35) ä¸­å¸Œå°‘:+2/å€‹
    """
    content_lower = content.lower()
    score = 0
    for kw in RARITY_HIGH:
        if kw.lower() in content_lower:
            score += 5
    for kw in RARITY_MED:
        if kw.lower() in content_lower:
            score += 2
    return min(score, 35)

def score_reliability(item: dict) -> int:
    """
    ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ (0-25 ç‚¹)
    é«˜ä¿¡é ¼ãƒ‰ãƒ¡ã‚¤ãƒ³:25 / ä¸­ä¿¡é ¼:15 / å…¬å¼Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆ:20 / ãã®ä»–:5
    """
    url    = item.get("source_url", "").lower()
    author = item.get("author", "").lower()
    source = item.get("source_type", "")

    # Googleã‚½ãƒ¼ã‚¹: ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¤å®š
    if source == "Google":
        for d in TRUST_HIGH_DOMAINS:
            if d in url:
                return 25
        for d in TRUST_MED_DOMAINS:
            if d in url:
                return 15
        return 5

    # Xã‚½ãƒ¼ã‚¹: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆååˆ¤å®š
    if source == "X":
        for kw in OFFICIAL_X_KEYWORDS:
            if kw in author:
                return 20
        return 8

    return 5

def compute_priority_level(total_score: int) -> str:
    """ã‚¹ã‚³ã‚¢ã‹ã‚‰å„ªå…ˆåº¦ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸"""
    if total_score >= 75: return "ğŸ”´ æœ€é‡è¦"
    if total_score >= 55: return "ğŸŸ  é«˜"
    if total_score >= 35: return "ğŸŸ¡ ä¸­"
    return "âšª ä½"

def score_item(item: dict) -> dict:
    """
    1ä»¶ã®ã‚¢ã‚¤ãƒ†ãƒ ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ã—ã¦è¿”ã™ã€‚
    è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: freshness_score, rarity_score, reliability_score,
                   total_score, priority_level
    """
    content = item.get("content", "")
    fresh   = score_freshness(item.get("date", ""))
    rarity  = score_rarity(content)
    trust   = score_reliability(item)
    total   = fresh + rarity + trust

    item["freshness_score"]   = fresh
    item["rarity_score"]      = rarity
    item["reliability_score"] = trust
    item["total_score"]       = total
    item["priority_level"]    = compute_priority_level(total)
    return item

def score_all(items: list) -> list:
    """å…¨ã‚¢ã‚¤ãƒ†ãƒ ã«ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ã—ã¦å„ªå…ˆåº¦é™é †ã§ã‚½ãƒ¼ãƒˆ"""
    scored = [score_item(dict(i)) for i in items]
    scored.sort(key=lambda x: x["total_score"], reverse=True)
    return scored

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆ
    test = [
        {
            "date": "2025-11-29",
            "content": "ä¸€ç•ªãã˜ DEATH NOTE æ•°é‡é™å®šï¼å—æ³¨ç”Ÿç”£ã€‚æ­»ç¥ãƒªãƒ¥ãƒ¼ã‚¯ã®ãƒ•ã‚£ã‚®ãƒ¥ã‚¢",
            "author": "1kuji.com",
            "source_url": "https://ichibankuji.com/test",
            "source_type": "Google"
        },
        {
            "date": "2024-01-01",
            "content": "ãƒ‡ã‚¹ãƒãƒ¼ãƒˆã‚°ãƒƒã‚ºç´¹ä»‹",
            "author": "user123",
            "source_url": "https://unknown.com/test",
            "source_type": "X"
        }
    ]
    for r in score_all(test):
        prio = r['priority_level'].encode('ascii', 'ignore').decode()
        print(f"[Score:{r['total_score']}] F:{r['freshness_score']} R:{r['rarity_score']} T:{r['reliability_score']} - {r['content'][:40]}")
